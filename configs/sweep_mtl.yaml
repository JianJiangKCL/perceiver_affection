project: perceiver_affection_hyper_mtl_trainval


program: main.py
name: mtl_seed
method: grid
parameters:
  depth:
    values: [5]

  num_latents:
    values: [256]
  latent_dim:
    values: [128]
  lr:
    values: [0.004]

  wandb_mode:
    values: ["online"]
  scheduler:
    values: ["constant"]
  optimizer:
        values: ["lamb"]
  seed:
    values: [1995]

  epochs:
    values: [25]

#  beta:
#    values: [0.1, 0.5, 1.0]
  alpha:
    values: [0.99]
#  finetune:
#    values: ["/vol/jj/proj/perceiver_affection/results/new_checkpoints2/text_facebody_audio_lr0.004_e60_seed1995_optlamb_bs128_beta0.5/last.ckpt"]
#
#  modalities:
#    values: ["text_facebody_audio"]
  finetune:
    values: [ "/home/rootuser/proj/perceiver_affection/results/first/xxx_lr0.004_e60_seed1995_optlamb_bs128_beta0.5/last.ckpt" ]

  modalities:
#    values: [ "text_facebody_audio", "text_audio_senti_speech_time"]
    values: ["text", "facebody", "audio", "senti_speech_time", "text_facebody", "text_facebody_audio_senti_speech_time", "text_facebody_senti_speech_time", "text_audio_senti_speech_time"]
  is_baseline:
    values: [0]

  use_distribution_loss:
    values: [1]

  results_dir:
    values: ["results/sweep_mtl_trainval_devicebul"]
  eval_every_n_epoch:
    values: [1]
metric:
  goal: minimize
  name: test_loss








