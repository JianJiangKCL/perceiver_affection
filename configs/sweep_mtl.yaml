project: perceiver_affection_spd_trainval_bul


program: main.py
name: mtl_seed
method: grid
parameters:
  depth:
    values: [5]

  num_latents:
    values: [256]
  latent_dim:
    values: [128]
  lr:
    values: [0.004]

  wandb_mode:
    values: ["online"]
  scheduler:
    values: ["constant"]
  optimizer:
        values: ["lamb"]
  seed:
    values: [1995]

  epochs:
    values: [10]

#  beta:
#    values: [0.1, 0.5, 1.0]
#  alpha:
#    values: [0.5,0.8, 0.9,0.1]
  # gamma bigger than 100 will have big impact on the val loss for audio
  gamma:
    values: [10]
#  finetune:
#    values: ["/vol/jj/proj/perceiver_affection/results/new_checkpoints2/text_facebody_audio_lr0.004_e60_seed1995_optlamb_bs128_beta0.5/last.ckpt"]
#
#  modalities:
#    values: ["text_facebody_audio"]
  finetune:
    values: [ "/home/rootuser/proj/perceiver_affection/results/trainval_bul/xxx_lr0.004_e100_seed1995_optlamb_bs128_beta0.5_alpha_0.1/last.ckpt" ]

  modalities:
#    values: [ "text_facebody_audio", "text_audio_senti_speech_time"]
    values:  [ "senti_speech_time", "text_facebody", "text_audio", "text_senti_speech_time", "facebody_audio", "facebody_senti_speech_time", "audio_senti_speech_time", "text_facebody_audio", "text_facebody_senti_speech_time", "text_audio_senti_speech_time", "facebody_audio_senti_speech_time", "text_facebody_audio_senti_speech_time"] #["text", "facebody", "audio"]
  is_baseline:
    values: [0]

  use_distribution_loss:
    values: [1]

  results_dir:
    values: ["results/sweep_spd_trainval_devicebul"]
  eval_every_n_epoch:
    values: [1]
metric:
  goal: minimize
  name: test_loss








