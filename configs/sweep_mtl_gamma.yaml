project: perceiver_affection_spd_trainval_3090_final
#project: perceiver_affection_spd_trainval_3090

program: main.py
name: mtl_seed
method: grid
parameters:
  arch:
    values: [ 'perceiver' ]
  depth:
    values: [5]

  num_latents:
    values: [128]
  latent_dim:
    values: [128]
  lr:
    values: [ 0.004] # lr 0.001 with gamma 5 is little bit low performance;

  wandb_mode:
    values: ["online"]
  scheduler:
    values: ["constant"]
  optimizer:
        values: ["lamb"]
  seed:
    values: [ 6, 1995, 1996]
  epochs:
    values: [5]
  # gamma bigger than 100 will have big impact on the val loss for audio
  gamma:
#    values: [2, 2.5, 3, 5]
    values: [ 0, 0.1, 1, 10, 100 ]
  batch_size:
    values: [128]
  finetune:
    values: [ "/DATA/jj/affection/results/trainval_3090_baseline_final/gender/xxx_lr0.004_e60_seedsss_optlamb_bs128_beta0.5_alpha_0.1_gamma_1_beta_0.5/last.ckpt" ]

  modalities:
#    values: [ "text"]
    values:  ["text", "facebody", "audio", "text_facebody", "text_audio", "facebody_audio", "text_facebody_audio"]
    #[  "text","facebody", "audio", "senti_speech_time", "text_facebody", "text_audio", "text_senti_speech_time", "facebody_audio", "facebody_senti_speech_time", "audio_senti_speech_time", "text_facebody_audio", "text_facebody_senti_speech_time", "text_audio_senti_speech_time", "facebody_audio_senti_speech_time", "text_facebody_audio_senti_speech_time"] #["text", "facebody", "audio"]
  is_baseline:
    values: [0]

  use_distribution_loss:
    values: [1]

  results_dir:
    values: ["/DATA/jj/affection/results/trainval_mtl_gamma"]

  eval_every_n_epoch:
    values: [1]
  target_sensitive_group:
    values: [ "age", "gender" ]
metric:
  goal: minimize
  name: test_loss








